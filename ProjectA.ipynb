{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 a: Web scrapping to get 124 github links\n",
    "Instruction to use selenium: https://towardsdatascience.com/how-to-use-selenium-to-web-scrape-with-example-80f9b23a843a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_12668\\2093498340.py:6: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Download and Access WebDriver\n",
    "# In my case, I download at the link: https://googlechromelabs.github.io/chrome-for-testing/#stable\n",
    "\n",
    "# Specify the path to the downloaded ChromeDriver\n",
    "driver_path = os.path.join(os.getcwd(), \"chromedriver-win64\", \"chromedriver.exe\")\n",
    "\n",
    "browser = webdriver.Chrome()\n",
    "cService = webdriver.ChromeService(executable_path=driver_path)\n",
    "driver = webdriver.Chrome(service=cService)\n",
    "\n",
    "# Access Website Via Python\n",
    "driver.get(\"http://aserg-ufmg.github.io/why-we-refactor/#/projects\")\n",
    "\n",
    "# driver.set_page_load_timeout(30)  # wait for the page to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "621\n",
      "                                               Project Creation Date Commits  \\\n",
      "0    https://github.com/JetBrains/intellij-communit...       9/30/11  162625   \n",
      "1                 https://github.com/JetBrains/MPS.git       8/15/11   66445   \n",
      "2    https://github.com/CyanogenMod/android_framewo...       5/13/13   62208   \n",
      "3       https://github.com/liferay/liferay-plugins.git       9/25/09   33929   \n",
      "4                   https://github.com/neo4j/neo4j.git      11/12/12   29187   \n",
      "..                                                 ...           ...     ...   \n",
      "119               https://github.com/zeromq/jeromq.git        8/1/12     316   \n",
      "120          https://github.com/bitfireAT/davdroid.git       8/25/13     291   \n",
      "121           https://github.com/bennidi/mbassador.git      10/23/12     236   \n",
      "122        https://github.com/novoda/android-demos.git       7/26/09     142   \n",
      "123               https://github.com/jfinal/jfinal.git       4/25/12     102   \n",
      "\n",
      "    Java Files Contributors  \n",
      "0        47552          306  \n",
      "1        19226           60  \n",
      "2         5482         2568  \n",
      "3         2024          344  \n",
      "4         4607          150  \n",
      "..         ...          ...  \n",
      "119        215           39  \n",
      "120        438           19  \n",
      "121        115           15  \n",
      "122         69           11  \n",
      "123        175            6  \n",
      "\n",
      "[124 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=[\"Project\", \"Creation Date\", \"Commits\", \"Java Files\", \"Contributors\"])  # creates master dataframe\n",
    "\n",
    "# Extract project rows from the table\n",
    "data = driver.find_elements(By.CLASS_NAME, \"ng-binding\")\n",
    "list_data = enumerate(data)\n",
    "\n",
    "print(len(list(list_data)))\n",
    "\n",
    "# Group data into chunks of 5 for each project\n",
    "rows = []\n",
    "for i in range(1, len(data), 5):\n",
    "    project_link = data[i].text\n",
    "    creation_date = data[i + 1].text\n",
    "    commits = data[i + 2].text\n",
    "    java_files = data[i + 3].text\n",
    "    contributors = data[i + 4].text\n",
    "\n",
    "    # Create a dictionary for each project\n",
    "    row = {\n",
    "        \"Project\": project_link,\n",
    "        \"Creation Date\": creation_date,\n",
    "        \"Commits\": commits,\n",
    "        \"Java Files\": java_files,\n",
    "        \"Contributors\": contributors,\n",
    "    }\n",
    "\n",
    "    # Append each row to the list\n",
    "    rows.append(row)\n",
    "\n",
    "# Use pd.concat to combine all rows into the DataFrame\n",
    "df = pd.concat([df, pd.DataFrame(rows)], ignore_index=True)\n",
    "\n",
    "# Output the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the browser once the data is collected\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 b: Divide 124 projects into 5 groups (Keep the last group with 24 projects), randomly select 2 projects from each group. Because we aim for the bonus point, we will do mining for all projects. \n",
    "- Hung: 1-25\n",
    "- Mazen: 26-50\n",
    "- Juuso: 51-75\n",
    "- Nicolas: 76-100\n",
    "- Bharu: 101-124"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't run this function, as it's used for randomly select 10 projects from 5 groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10  25  45  50  58  70  78  91 106 114]\n",
      "Selected projects to work with:\n",
      "Project_10\n",
      "Project_25\n",
      "Project_45\n",
      "Project_50\n",
      "Project_58\n",
      "Project_70\n",
      "Project_78\n",
      "Project_91\n",
      "Project_106\n",
      "Project_114\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from numpy import sort\n",
    "# List of 124 project names (example list, you can replace it with actual project names)\n",
    "projects = [f\"{i+1}\" for i in range(124)]\n",
    "\n",
    "# Divide projects into 5 groups, with first 4 groups contain 25 projects each\n",
    "group_size = 25\n",
    "groups = [projects[i : i + group_size] for i in range(0, 100, group_size)]\n",
    "# Add the remaining 24 projects as the last group\n",
    "groups.append(projects[100:])\n",
    "\n",
    "# Randomly select 2 projects from each group\n",
    "selected_projects = []\n",
    "for group in groups:\n",
    "    selected_projects.extend(random.sample(group, 2))\n",
    "\n",
    "selected_projects = [int(project) for project in selected_projects] # Convert to int for sorting\n",
    "selected_projects = sort(selected_projects)\n",
    "\n",
    "print(selected_projects)\n",
    "# Output the selected 10 projects\n",
    "print(\"Selected projects to work with:\")\n",
    "for project in selected_projects:\n",
    "    print(\"Project_\"+str(project))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lists of project that you are assigned to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n"
     ]
    }
   ],
   "source": [
    "Start = 1\n",
    "End = 25\n",
    "selected_projects = [i for i in range(Start, End+1)]\n",
    "\n",
    "print(selected_projects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get github links that we generate above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://github.com/JetBrains/intellij-community.git\n",
      "https://github.com/JetBrains/MPS.git\n",
      "https://github.com/CyanogenMod/android_frameworks_base.git\n",
      "https://github.com/liferay/liferay-plugins.git\n",
      "https://github.com/neo4j/neo4j.git\n",
      "https://github.com/apache/camel.git\n",
      "https://github.com/gradle/gradle.git\n",
      "https://github.com/processing/processing.git\n",
      "https://github.com/elastic/elasticsearch.git\n",
      "https://github.com/belaban/JGroups.git\n",
      "https://github.com/osmandapp/Osmand.git\n",
      "https://github.com/wildfly/wildfly.git\n",
      "https://github.com/SonarSource/sonarqube.git\n",
      "https://github.com/VoltDB/voltdb.git\n",
      "https://github.com/languagetool-org/languagetool.git\n",
      "https://github.com/grails/grails-core.git\n",
      "https://github.com/apache/hive.git\n",
      "https://github.com/fabric8io/fabric8.git\n",
      "https://github.com/hazelcast/hazelcast.git\n",
      "https://github.com/apache/cassandra.git\n",
      "https://github.com/rstudio/rstudio.git\n",
      "https://github.com/spring-projects/spring-framework.git\n",
      "https://github.com/droolsjbpm/drools.git\n",
      "https://github.com/BroadleafCommerce/BroadleafCommerce.git\n",
      "https://github.com/eclipse/jetty.project.git\n"
     ]
    }
   ],
   "source": [
    "project_links = []\n",
    "\n",
    "for project in selected_projects:\n",
    "    project_link = df.loc[project - 1, \"Project\"]\n",
    "    project_links.append(project_link)\n",
    "\n",
    "# Print the project links\n",
    "for link in project_links:\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get repo name for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['intellij-community', 'MPS', 'android_frameworks_base', 'liferay-plugins', 'neo4j', 'camel', 'gradle', 'processin', 'elasticsearch', 'JGroups', 'Osmand', 'wildfly', 'sonarqube', 'voltdb', 'languagetool', 'grails-core', 'hive', 'fabric8', 'hazelcas', 'cassandra', 'rstudio', 'spring-framework', 'drools', 'BroadleafCommerce', 'jetty.projec']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "pwd = os.getcwd()\n",
    "\n",
    "repo_names = []\n",
    "\n",
    "for link in project_links:\n",
    "    # Get the clean repo name by splitting the URL and removing \".git\"\n",
    "    repo_suffix = link.split(\"/\")[-1]\n",
    "    repo_name = repo_suffix.rstrip(\".git\")\n",
    "    repo_names.append(repo_name)\n",
    "\n",
    "print(repo_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clone 25 github repos to local machine. We will do for 5 repos each turn.\n",
    "\n",
    "Note that you might face error when cloning that returned non-zero exit status 128. If so, fix it by run cmd as admin, run \"git config --system core.longpaths true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning project JGroups\n",
      "Project JGroups cloned\n",
      "Cloning project jetty.projec\n",
      "Project jetty.projec cloned\n",
      "Cloning project Activ\n",
      "Project Activ cloned\n",
      "Cloning project spring-roo\n",
      "Project spring-roo cloned\n",
      "Cloning project open-keychain\n",
      "Project open-keychain cloned\n",
      "Cloning project Android-IMSI-Catcher-Detector\n",
      "Project Android-IMSI-Catcher-Detector cloned\n",
      "Cloning project android\n",
      "Project android cloned\n",
      "Cloning project spring-data-neo4j\n",
      "Project spring-data-neo4j cloned\n",
      "Cloning project RoboBindin\n",
      "Project RoboBindin cloned\n",
      "Cloning project sshj\n",
      "Project sshj cloned\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "pwd = os.getcwd()\n",
    "\n",
    "for link in project_links:\n",
    "    # Get the clean repo name by splitting the URL and removing \".git\"\n",
    "    repo_suffix = link.split(\"/\")[-1]\n",
    "    repo_name = repo_suffix.rstrip(\".git\")\n",
    "    # Path to the target directory where the repository will be cloned\n",
    "    repo_path = os.path.join(pwd, \"RepoFolder\", repo_name)\n",
    "\n",
    "    # Cloning the project into the current working directory\n",
    "    # Check if the directory already exists\n",
    "\n",
    "    print(f\"Cloning project {repo_name}\")\n",
    "    # Cloning the project with error handling\n",
    "    try:\n",
    "        subprocess.run([\"git\", \"clone\", link, repo_path], check=True)\n",
    "        print(f\"Project {repo_name} cloned\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error cloning {repo_name}: {e}\")\n",
    "        continue  # Skip to the next repository if cloning fails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't run it for now, keep it last \n",
    "\n",
    "Delete projects to free memory (you can do it manually at last :D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo path:  d:\\Oulun\\Period 5\\Software development, Maintenance and Operation\\Projects\\RepoFolder\n"
     ]
    }
   ],
   "source": [
    "import stat\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def remove_readonly(func, path, _):\n",
    "    \"Clear the readonly bit and reattempt the removal\"\n",
    "    os.chmod(path, stat.S_IWRITE)\n",
    "    func(path)\n",
    "\n",
    "\n",
    "repo_path = os.path.join(pwd, \"RepoFolder\")\n",
    "print(\"Repo path: \", repo_path)\n",
    "\n",
    "# Clean up: Remove the cloned repository\n",
    "if os.path.exists(repo_path):\n",
    "    shutil.rmtree(repo_path, onerror=remove_readonly)\n",
    "    \n",
    "print(f\"Projects erased\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 c: Mine the refactoring activity applied in the history of the cloned projects using RefactoringMiner library\n",
    "You can read more here: https://github.com/tsantalis/RefactoringMiner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: First thing first, download RefactoringMiner library\n",
    "- Link and instruction to download: https://github.com/tsantalis/RefactoringMiner/releases\n",
    "- I use version 3.0.8: https://github.com/tsantalis/RefactoringMiner/releases/download/3.0.8/RefactoringMiner-3.0.8.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Step 2: Add path of bin to system environment variables\n",
    "Search google if you don't know how to add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Make sure it run normally\n",
    "Make sure you have Java installed on your computer. If you don't, download it here: https://www.oracle.com/java/technologies/javase/jdk17-archive-downloads.html\n",
    "\n",
    "Then try to run this command line:\n",
    "> git clone https://github.com/danilofes/refactoring-toy-example.git refactoring-toy-example\n",
    "\n",
    "> RefactoringMiner -c refactoring-toy-example 36287f7c3b09eff78395267a3ac0d7da067863fd -json result.json\n",
    "\n",
    "Since release 3.0.0, RefactoringMiner requires Java 17 or newer and Gradle 7.4 or newer\n",
    "\n",
    "> RefactoringMiner diff --url https://github.com/JabRef/jabref/pull/11180\n",
    "\n",
    "To run the command above, you must provide a valid OAuth token in the github-oauth.properties file stored in the bin folder. You can generate an OAuth token in GitHub Settings -> Developer settings -> Personal access tokens. Together with creating a file named .github in your home directory (C:\\Users\\ADMIN\\.github for Windows).\n",
    "\n",
    "The file should contain your GitHub credentials (personal access token or username/password). The format should look like: \n",
    "\n",
    "> login=your_github_username\n",
    "\n",
    "> oauth=your_github_personal_access_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Run RefactoringMiner on the cloned repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RepoFolder\\\\JGroups', 'RepoFolder\\\\jetty.projec', 'RepoFolder\\\\Activ', 'RepoFolder\\\\spring-roo', 'RepoFolder\\\\open-keychain', 'RepoFolder\\\\Android-IMSI-Catcher-Detector', 'RepoFolder\\\\android', 'RepoFolder\\\\spring-data-neo4j', 'RepoFolder\\\\RoboBindin', 'RepoFolder\\\\sshj']\n"
     ]
    }
   ],
   "source": [
    "# Now we are ready to look at data dimension to be mined\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# repo_paths = [os.path.join(os.getcwd(), \"RepoFolder\", i) for i in repo_names]\n",
    "repo_paths = [os.path.join(\"RepoFolder\", i) for i in repo_names]\n",
    "\n",
    "print(repo_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling for repo number 1 :\n",
      "Handling for repo number 2 :\n",
      "Handling for repo number 3 :\n",
      "Handling for repo number 4 :\n",
      "Handling for repo number 5 :\n",
      "Handling for repo number 6 :\n",
      "Handling for repo number 7 :\n",
      "Handling for repo number 8 :\n",
      "Handling for repo number 9 :\n",
      "Handling for repo number 10 :\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Create the directory for saving results if it doesn't already exist\n",
    "os.makedirs(\"RefactoringMiner-Result\", exist_ok=True)\n",
    "\n",
    "def run_command(command, repo_path):\n",
    "    try:\n",
    "        subprocess.run(command, check=True, shell=True)\n",
    "        print(f\"Refactoring mined for {repo_path} saved in {save_dir}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error mining refactoring for {repo_path}: {e}\")\n",
    "\n",
    "# Run analysis in parallel using ThreadPoolExecutor\n",
    "with ThreadPoolExecutor(\n",
    "    max_workers=4\n",
    ") as executor:  # You can adjust the number of workers\n",
    "    for idx, repo_path in enumerate(repo_paths):\n",
    "        print(f\"Handling for repo number {idx+1}\")\n",
    "        save_dir = os.path.join(\"RefactoringMiner-Result\", f\"{repo_names[idx]}.json\")\n",
    "        command = [\"RefactoringMiner\", \"-a\", repo_path, \"-json\", save_dir]\n",
    "        executor.submit(run_command, command, repo_path)\n",
    "        \n",
    "print(\"Finished mining data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 d: Collect the commit message from the commits where refactoring activity has been detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
